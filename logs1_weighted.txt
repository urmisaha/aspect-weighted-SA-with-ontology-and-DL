Processing text dataset
len(aspect_term_list) 1295
counts:
overall positive sentences:  2389
overall negative sentences:  655
food_count =  2030    pos:  1561   neg:  469
service_count =  933  pos:  516    neg:  417
price_count =  427  pos:  242      neg:  185
ambience_count =  666    pos:  433   neg:  233
misc_count =  2125    pos:  1705   neg:  420

matrix:
food:  {'pp': 0.7571428571428571, 'pn': 0.011822660098522168, 'np': 0.06945812807881774, 'nn': 0.16157635467980297}
service:  {'pp': 0.5423365487674169, 'pn': 0.010718113612004287, 'np': 0.10503751339764202, 'nn': 0.34190782422293675}
price:  {'pp': 0.5597189695550351, 'pn': 0.00702576112412178, 'np': 0.12646370023419204, 'nn': 0.30679156908665106}
ambience:  {'pp': 0.6351351351351351, 'pn': 0.015015015015015015, 'np': 0.13963963963963963, 'nn': 0.21021021021021022}
misc:  {'pp': 0.7905882352941176, 'pn': 0.011764705882352941, 'np': 0.03811764705882353, 'nn': 0.1595294117647059}

aspect_weights:
{'food': 0.9187192118226601, 'service': 0.8842443729903536, 'price': 0.8665105386416861, 'ambience': 0.8453453453453453, 'misc': 0.9501176470588235}
dataframe.shape =  (3801, 2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 40, 20)            88540     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               48400     
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 202       
=================================================================
Total params: 137,142
Trainable params: 137,142
Non-trainable params: 0
_________________________________________________________________
None
Train on 3801 samples, validate on 3801 samples
Epoch 1/5

 128/3801 [>.............................] - ETA: 18s - loss: 0.7024 - acc: 0.4375
 256/3801 [=>............................] - ETA: 9s - loss: 0.7034 - acc: 0.4570 
 512/3801 [===>..........................] - ETA: 5s - loss: 0.7022 - acc: 0.4531
 640/3801 [====>.........................] - ETA: 4s - loss: 0.6990 - acc: 0.4750
 768/3801 [=====>........................] - ETA: 3s - loss: 0.6982 - acc: 0.4818
 896/3801 [======>.......................] - ETA: 3s - loss: 0.6979 - acc: 0.4799
1024/3801 [=======>......................] - ETA: 2s - loss: 0.6972 - acc: 0.4834
1280/3801 [=========>....................] - ETA: 2s - loss: 0.6950 - acc: 0.5016
1536/3801 [===========>..................] - ETA: 1s - loss: 0.6951 - acc: 0.5046
1792/3801 [=============>................] - ETA: 1s - loss: 0.6950 - acc: 0.5061
2048/3801 [===============>..............] - ETA: 1s - loss: 0.6944 - acc: 0.5098
2304/3801 [=================>............] - ETA: 0s - loss: 0.6940 - acc: 0.5139
2560/3801 [===================>..........] - ETA: 0s - loss: 0.6931 - acc: 0.5188
2816/3801 [=====================>........] - ETA: 0s - loss: 0.6923 - acc: 0.5227
3072/3801 [=======================>......] - ETA: 0s - loss: 0.6913 - acc: 0.5303
3328/3801 [=========================>....] - ETA: 0s - loss: 0.6906 - acc: 0.5328
3456/3801 [==========================>...] - ETA: 0s - loss: 0.6903 - acc: 0.5333
3584/3801 [===========================>..] - ETA: 0s - loss: 0.6892 - acc: 0.5366
3712/3801 [============================>.] - ETA: 0s - loss: 0.6898 - acc: 0.5361
3801/3801 [==============================] - 3s 704us/step - loss: 0.6895 - acc: 0.5378 - val_loss: 0.6910 - val_acc: 0.5393
Epoch 2/5

 128/3801 [>.............................] - ETA: 1s - loss: 0.6788 - acc: 0.5625
 384/3801 [==>...........................] - ETA: 1s - loss: 0.6785 - acc: 0.5677
 512/3801 [===>..........................] - ETA: 1s - loss: 0.6797 - acc: 0.5605
 640/3801 [====>.........................] - ETA: 1s - loss: 0.6799 - acc: 0.5625
 768/3801 [=====>........................] - ETA: 1s - loss: 0.6790 - acc: 0.5716
1024/3801 [=======>......................] - ETA: 1s - loss: 0.6829 - acc: 0.5645
1280/3801 [=========>....................] - ETA: 0s - loss: 0.6855 - acc: 0.5539
1536/3801 [===========>..................] - ETA: 0s - loss: 0.6845 - acc: 0.5527
1792/3801 [=============>................] - ETA: 0s - loss: 0.6857 - acc: 0.5485
2048/3801 [===============>..............] - ETA: 0s - loss: 0.6844 - acc: 0.5537
2304/3801 [=================>............] - ETA: 0s - loss: 0.6832 - acc: 0.5556
2560/3801 [===================>..........] - ETA: 0s - loss: 0.6814 - acc: 0.5641
2688/3801 [====================>.........] - ETA: 0s - loss: 0.6819 - acc: 0.5625
2944/3801 [======================>.......] - ETA: 0s - loss: 0.6802 - acc: 0.5676
3072/3801 [=======================>......] - ETA: 0s - loss: 0.6799 - acc: 0.5693
3200/3801 [========================>.....] - ETA: 0s - loss: 0.6804 - acc: 0.5678
3456/3801 [==========================>...] - ETA: 0s - loss: 0.6802 - acc: 0.5680
3712/3801 [============================>.] - ETA: 0s - loss: 0.6806 - acc: 0.5673
3801/3801 [==============================] - 2s 518us/step - loss: 0.6801 - acc: 0.5688 - val_loss: 0.6701 - val_acc: 0.5964
Epoch 3/5

 128/3801 [>.............................] - ETA: 1s - loss: 0.6729 - acc: 0.6406
 384/3801 [==>...........................] - ETA: 1s - loss: 0.6712 - acc: 0.6016
 512/3801 [===>..........................] - ETA: 1s - loss: 0.6699 - acc: 0.5957
 640/3801 [====>.........................] - ETA: 1s - loss: 0.6652 - acc: 0.6047
 896/3801 [======>.......................] - ETA: 1s - loss: 0.6687 - acc: 0.5882
1024/3801 [=======>......................] - ETA: 1s - loss: 0.6677 - acc: 0.5879
1280/3801 [=========>....................] - ETA: 0s - loss: 0.6669 - acc: 0.5875
1536/3801 [===========>..................] - ETA: 0s - loss: 0.6683 - acc: 0.5879
1664/3801 [============>.................] - ETA: 0s - loss: 0.6666 - acc: 0.5950
1792/3801 [=============>................] - ETA: 0s - loss: 0.6655 - acc: 0.5982
1920/3801 [==============>...............] - ETA: 0s - loss: 0.6654 - acc: 0.5974
2048/3801 [===============>..............] - ETA: 0s - loss: 0.6642 - acc: 0.5981
2304/3801 [=================>............] - ETA: 0s - loss: 0.6628 - acc: 0.5955
2560/3801 [===================>..........] - ETA: 0s - loss: 0.6595 - acc: 0.6031
2816/3801 [=====================>........] - ETA: 0s - loss: 0.6565 - acc: 0.6097
2944/3801 [======================>.......] - ETA: 0s - loss: 0.6556 - acc: 0.6128
3200/3801 [========================>.....] - ETA: 0s - loss: 0.6516 - acc: 0.6228
3456/3801 [==========================>...] - ETA: 0s - loss: 0.6475 - acc: 0.6276
3584/3801 [===========================>..] - ETA: 0s - loss: 0.6543 - acc: 0.6225
3712/3801 [============================>.] - ETA: 0s - loss: 0.6509 - acc: 0.6277
3801/3801 [==============================] - 2s 537us/step - loss: 0.6508 - acc: 0.6275 - val_loss: 0.6187 - val_acc: 0.6664
Epoch 4/5

 128/3801 [>.............................] - ETA: 1s - loss: 0.6445 - acc: 0.6875
 256/3801 [=>............................] - ETA: 1s - loss: 0.6118 - acc: 0.7266
 384/3801 [==>...........................] - ETA: 1s - loss: 0.5998 - acc: 0.7344
 512/3801 [===>..........................] - ETA: 1s - loss: 0.5908 - acc: 0.7500
 768/3801 [=====>........................] - ETA: 1s - loss: 0.5871 - acc: 0.7396
1024/3801 [=======>......................] - ETA: 1s - loss: 0.5904 - acc: 0.7217
1152/3801 [========>.....................] - ETA: 1s - loss: 0.5884 - acc: 0.7205
1280/3801 [=========>....................] - ETA: 1s - loss: 0.5859 - acc: 0.7258
1408/3801 [==========>...................] - ETA: 0s - loss: 0.5842 - acc: 0.7351
1536/3801 [===========>..................] - ETA: 0s - loss: 0.5820 - acc: 0.7428
1792/3801 [=============>................] - ETA: 0s - loss: 0.5789 - acc: 0.7500
1920/3801 [==============>...............] - ETA: 0s - loss: 0.5773 - acc: 0.7521
2048/3801 [===============>..............] - ETA: 0s - loss: 0.5767 - acc: 0.7510
2176/3801 [================>.............] - ETA: 0s - loss: 0.5752 - acc: 0.7528
2304/3801 [=================>............] - ETA: 0s - loss: 0.5742 - acc: 0.7517
2432/3801 [==================>...........] - ETA: 0s - loss: 0.5746 - acc: 0.7500
2560/3801 [===================>..........] - ETA: 0s - loss: 0.5733 - acc: 0.7516
2816/3801 [=====================>........] - ETA: 0s - loss: 0.5694 - acc: 0.7560
2944/3801 [======================>.......] - ETA: 0s - loss: 0.5676 - acc: 0.7592
3072/3801 [=======================>......] - ETA: 0s - loss: 0.5658 - acc: 0.7604
3200/3801 [========================>.....] - ETA: 0s - loss: 0.5645 - acc: 0.7616
3328/3801 [=========================>....] - ETA: 0s - loss: 0.5610 - acc: 0.7650
3456/3801 [==========================>...] - ETA: 0s - loss: 0.5591 - acc: 0.7645
3712/3801 [============================>.] - ETA: 0s - loss: 0.5526 - acc: 0.7702
3801/3801 [==============================] - 2s 562us/step - loss: 0.5490 - acc: 0.7727 - val_loss: 0.3996 - val_acc: 0.8769
Epoch 5/5

 128/3801 [>.............................] - ETA: 1s - loss: 0.4324 - acc: 0.8594
 256/3801 [=>............................] - ETA: 1s - loss: 0.4049 - acc: 0.8555
 384/3801 [==>...........................] - ETA: 1s - loss: 0.4179 - acc: 0.8281
 512/3801 [===>..........................] - ETA: 1s - loss: 0.4491 - acc: 0.7930
 640/3801 [====>.........................] - ETA: 1s - loss: 0.4524 - acc: 0.7828
 768/3801 [=====>........................] - ETA: 1s - loss: 0.5037 - acc: 0.7474
 896/3801 [======>.......................] - ETA: 1s - loss: 0.5106 - acc: 0.7444
1024/3801 [=======>......................] - ETA: 1s - loss: 0.5105 - acc: 0.7451
1280/3801 [=========>....................] - ETA: 1s - loss: 0.4974 - acc: 0.7625
1536/3801 [===========>..................] - ETA: 0s - loss: 0.5019 - acc: 0.7604
1792/3801 [=============>................] - ETA: 0s - loss: 0.4926 - acc: 0.7628
1920/3801 [==============>...............] - ETA: 0s - loss: 0.4902 - acc: 0.7625
2176/3801 [================>.............] - ETA: 0s - loss: 0.4781 - acc: 0.7757
2304/3801 [=================>............] - ETA: 0s - loss: 0.4758 - acc: 0.7808
2432/3801 [==================>...........] - ETA: 0s - loss: 0.4710 - acc: 0.7850
2560/3801 [===================>..........] - ETA: 0s - loss: 0.4657 - acc: 0.7902
2688/3801 [====================>.........] - ETA: 0s - loss: 0.4616 - acc: 0.7943
2816/3801 [=====================>........] - ETA: 0s - loss: 0.4587 - acc: 0.7976
3072/3801 [=======================>......] - ETA: 0s - loss: 0.4562 - acc: 0.7995
3200/3801 [========================>.....] - ETA: 0s - loss: 0.4520 - acc: 0.8034
3328/3801 [=========================>....] - ETA: 0s - loss: 0.4495 - acc: 0.8062
3456/3801 [==========================>...] - ETA: 0s - loss: 0.4455 - acc: 0.8087
3584/3801 [===========================>..] - ETA: 0s - loss: 0.4426 - acc: 0.8103
3712/3801 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8144
3801/3801 [==============================] - 2s 549us/step - loss: 0.4336 - acc: 0.8166 - val_loss: 0.3074 - val_acc: 0.8885
predictions =  [[0.93816113 0.06183892]
 [0.293406   0.706594  ]
 [0.61500543 0.38499454]
 ...
 [0.8701327  0.12986737]
 [0.04917916 0.9508208 ]
 [0.2347469  0.76525307]]
predictions1 =  [1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]
Scores calculated from sklearn::
accuracy_score:  0.2720105124835742
precision_score:  0.5739130434782609
recall_score:  0.22448979591836735

Classification Report:
             precision    recall  f1-score   support

          0       0.14      0.43      0.21       173
          1       0.57      0.22      0.32       588

avg / total       0.48      0.27      0.30       761

