Processing text dataset
len(aspect_term_list) 748
counts:
overall positive sentences:  1115
overall negative sentences:  346
food_count =  1029    pos:  769   neg:  260
service_count =  429  pos:  236    neg:  193
price_count =  205  pos:  119      neg:  86
ambience_count =  299    pos:  192   neg:  107
misc_count =  999    pos:  781   neg:  218

matrix:
food:  {'pp': 0.738581146744412, 'pn': 0.008746355685131196, 'np': 0.062196307094266275, 'nn': 0.19047619047619047}
service:  {'pp': 0.5361305361305362, 'pn': 0.013986013986013986, 'np': 0.055944055944055944, 'nn': 0.3939393939393939}
price:  {'pp': 0.5658536585365853, 'pn': 0.014634146341463415, 'np': 0.11219512195121951, 'nn': 0.3073170731707317}
ambience:  {'pp': 0.6254180602006689, 'pn': 0.016722408026755852, 'np': 0.1605351170568562, 'nn': 0.19732441471571907}
misc:  {'pp': 0.7717717717717718, 'pn': 0.01001001001001001, 'np': 0.037037037037037035, 'nn': 0.18118118118118118}

aspect_weights:
{'food': 0.9290573372206025, 'service': 0.9300699300699301, 'price': 0.873170731707317, 'ambience': 0.822742474916388, 'misc': 0.952952952952953}
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 40, 20)            58700     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               48400     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 101       
=================================================================
Total params: 107,201
Trainable params: 107,201
Non-trainable params: 0
_________________________________________________________________
None
Train on 1096 samples, validate on 1096 samples
Epoch 1/5

 128/1096 [==>...........................] - ETA: 5s - loss: 0.7032 - acc: 0.2656 - precision: 1.0000 - recall: 0.0408 - f2_score: 0.0312
 256/1096 [======>.......................] - ETA: 2s - loss: 0.6882 - acc: 0.5273 - precision: 0.8945 - recall: 0.5204 - f2_score: 0.4102
 512/1096 [=============>................] - ETA: 1s - loss: 0.6641 - acc: 0.6426 - precision: 0.8262 - recall: 0.7602 - f2_score: 0.5840
 768/1096 [====================>.........] - ETA: 0s - loss: 0.6454 - acc: 0.6719 - precision: 0.7943 - recall: 0.8401 - f2_score: 0.6328
 896/1096 [=======================>......] - ETA: 0s - loss: 0.6317 - acc: 0.6886 - precision: 0.7935 - recall: 0.8630 - f2_score: 0.6551
1024/1096 [===========================>..] - ETA: 0s - loss: 0.6249 - acc: 0.6953 - precision: 0.7871 - recall: 0.8801 - f2_score: 0.6660
1096/1096 [==============================] - 1s 1ms/step - loss: 0.6129 - acc: 0.7062 - precision: 0.7920 - recall: 0.8880 - f2_score: 0.6788 - val_loss: 0.5478 - val_acc: 0.7646 - val_precision: 0.7646 - val_recall: 1.0000 - val_f2_score: 0.7646
Epoch 2/5

 128/1096 [==>...........................] - ETA: 0s - loss: 0.5242 - acc: 0.7812 - precision: 0.7812 - recall: 1.0000 - f2_score: 0.7812
 384/1096 [=========>....................] - ETA: 0s - loss: 0.5964 - acc: 0.7422 - precision: 0.7422 - recall: 1.0000 - f2_score: 0.7422
 640/1096 [================>.............] - ETA: 0s - loss: 0.6012 - acc: 0.7359 - precision: 0.7359 - recall: 1.0000 - f2_score: 0.7359
 768/1096 [====================>.........] - ETA: 0s - loss: 0.5937 - acc: 0.7396 - precision: 0.7396 - recall: 1.0000 - f2_score: 0.7396
1024/1096 [===========================>..] - ETA: 0s - loss: 0.5645 - acc: 0.7607 - precision: 0.7607 - recall: 1.0000 - f2_score: 0.7607
1096/1096 [==============================] - 1s 569us/step - loss: 0.5592 - acc: 0.7646 - precision: 0.7646 - recall: 1.0000 - f2_score: 0.7646 - val_loss: 0.5430 - val_acc: 0.7646 - val_precision: 0.7646 - val_recall: 1.0000 - val_f2_score: 0.7646
Epoch 3/5

 128/1096 [==>...........................] - ETA: 0s - loss: 0.5613 - acc: 0.7500 - precision: 0.7500 - recall: 1.0000 - f2_score: 0.7500
 256/1096 [======>.......................] - ETA: 0s - loss: 0.5498 - acc: 0.7578 - precision: 0.7578 - recall: 1.0000 - f2_score: 0.7578
 512/1096 [=============>................] - ETA: 0s - loss: 0.5477 - acc: 0.7598 - precision: 0.7598 - recall: 1.0000 - f2_score: 0.7598
 640/1096 [================>.............] - ETA: 0s - loss: 0.5411 - acc: 0.7656 - precision: 0.7656 - recall: 1.0000 - f2_score: 0.7656
 768/1096 [====================>.........] - ETA: 0s - loss: 0.5340 - acc: 0.7721 - precision: 0.7721 - recall: 1.0000 - f2_score: 0.7721
 896/1096 [=======================>......] - ETA: 0s - loss: 0.5413 - acc: 0.7656 - precision: 0.7656 - recall: 1.0000 - f2_score: 0.7656
1024/1096 [===========================>..] - ETA: 0s - loss: 0.5393 - acc: 0.7676 - precision: 0.7676 - recall: 1.0000 - f2_score: 0.7676
1096/1096 [==============================] - 1s 769us/step - loss: 0.5425 - acc: 0.7646 - precision: 0.7646 - recall: 1.0000 - f2_score: 0.7646 - val_loss: 0.5392 - val_acc: 0.7646 - val_precision: 0.7646 - val_recall: 1.0000 - val_f2_score: 0.7646
Epoch 4/5

 128/1096 [==>...........................] - ETA: 0s - loss: 0.5086 - acc: 0.7891 - precision: 0.7891 - recall: 1.0000 - f2_score: 0.7891
 256/1096 [======>.......................] - ETA: 0s - loss: 0.5047 - acc: 0.7930 - precision: 0.7930 - recall: 1.0000 - f2_score: 0.7930
 384/1096 [=========>....................] - ETA: 0s - loss: 0.5058 - acc: 0.7917 - precision: 0.7917 - recall: 1.0000 - f2_score: 0.7917
 640/1096 [================>.............] - ETA: 0s - loss: 0.5152 - acc: 0.7844 - precision: 0.7844 - recall: 1.0000 - f2_score: 0.7844
 896/1096 [=======================>......] - ETA: 0s - loss: 0.5312 - acc: 0.7712 - precision: 0.7712 - recall: 1.0000 - f2_score: 0.7712
1024/1096 [===========================>..] - ETA: 0s - loss: 0.5410 - acc: 0.7637 - precision: 0.7637 - recall: 1.0000 - f2_score: 0.7637
1096/1096 [==============================] - 1s 578us/step - loss: 0.5396 - acc: 0.7646 - precision: 0.7646 - recall: 1.0000 - f2_score: 0.7646 - val_loss: 0.5366 - val_acc: 0.7646 - val_precision: 0.7646 - val_recall: 1.0000 - val_f2_score: 0.7646
Epoch 5/5

 128/1096 [==>...........................] - ETA: 0s - loss: 0.5150 - acc: 0.7812 - precision: 0.7812 - recall: 1.0000 - f2_score: 0.7812
 256/1096 [======>.......................] - ETA: 0s - loss: 0.5156 - acc: 0.7812 - precision: 0.7812 - recall: 1.0000 - f2_score: 0.7812
 384/1096 [=========>....................] - ETA: 0s - loss: 0.5424 - acc: 0.7604 - precision: 0.7604 - recall: 1.0000 - f2_score: 0.7604
 512/1096 [=============>................] - ETA: 0s - loss: 0.5310 - acc: 0.7695 - precision: 0.7695 - recall: 1.0000 - f2_score: 0.7695
 640/1096 [================>.............] - ETA: 0s - loss: 0.5399 - acc: 0.7625 - precision: 0.7625 - recall: 1.0000 - f2_score: 0.7625
 768/1096 [====================>.........] - ETA: 0s - loss: 0.5347 - acc: 0.7669 - precision: 0.7669 - recall: 1.0000 - f2_score: 0.7669
 896/1096 [=======================>......] - ETA: 0s - loss: 0.5406 - acc: 0.7612 - precision: 0.7612 - recall: 1.0000 - f2_score: 0.7612
1024/1096 [===========================>..] - ETA: 0s - loss: 0.5337 - acc: 0.7666 - precision: 0.7666 - recall: 1.0000 - f2_score: 0.7666
1096/1096 [==============================] - 1s 609us/step - loss: 0.5354 - acc: 0.7646 - precision: 0.7646 - recall: 1.0000 - f2_score: 0.7646 - val_loss: 0.5335 - val_acc: 0.7646 - val_precision: 0.7646 - val_recall: 1.0000 - val_f2_score: 0.7646
Y_test =  [0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1
 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1
 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1
 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1
 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1
 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1
 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1
 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1
 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0
 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1]
predictions1 =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Scores calculated from sklearn::
accuracy_score:  0.7589041095890411
precision_score:  0.7589041095890411
recall_score:  1.0

Classification Report:
             precision    recall  f1-score   support

          0       0.00      0.00      0.00        88
          1       0.76      1.00      0.86       277

avg / total       0.58      0.76      0.65       365

