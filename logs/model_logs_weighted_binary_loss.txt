Processing text dataset
len(aspect_term_list) 466

aspect_weights:
{'food': 0.9414893617021276, 'service': 0.9362549800796812, 'price': 0.8719999999999999, 'ambience': 0.7804878048780488, 'misc': 0.9691252144082332}
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0  259    1 1046  311   34]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    7  260  380 1047   26   19   20   12    5 1048    0]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0  282    1  143    9   39  496    4   91    0]
 [   0    0    0    0    0    0    0    0    0    0    0  933   35  380
  1028    1  114    0    0    9    1   14   72    9  821  569   24  553
     6   27  124  101   11   46    1  104    0    8    0    0]]
predicted_positives =  Tensor("metrics/precision/Sum_1:0", shape=(), dtype=float32)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 40, 20)            42380     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               48400     
_________________________________________________________________
dense_1 (Dense)              (None, 100)               10100     
_________________________________________________________________
batch_normalization_1 (Batch (None, 100)               400       
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
=================================================================
Total params: 101,381
Trainable params: 101,181
Non-trainable params: 200
_________________________________________________________________
None
Train on 624 samples, validate on 624 samples
Epoch 1/5

128/624 [=====>........................] - ETA: 3s - loss: 0.7471 - acc: 0.4531 - precision: 0.7385
256/624 [===========>..................] - ETA: 1s - loss: 0.7174 - acc: 0.5117 - precision: 0.7648
384/624 [=================>............] - ETA: 0s - loss: 0.7118 - acc: 0.5312 - precision: 0.7792
624/624 [==============================] - 1s 2ms/step - loss: 0.7126 - acc: 0.5353 - precision: 0.7768 - val_loss: 0.7205 - val_acc: 0.4263 - val_precision: 0.8293
Epoch 2/5

128/624 [=====>........................] - ETA: 0s - loss: 0.6832 - acc: 0.6016 - precision: 0.8101
256/624 [===========>..................] - ETA: 0s - loss: 0.6826 - acc: 0.6133 - precision: 0.7909
384/624 [=================>............] - ETA: 0s - loss: 0.6813 - acc: 0.6120 - precision: 0.7865
512/624 [=======================>......] - ETA: 0s - loss: 0.6804 - acc: 0.6152 - precision: 0.7844
624/624 [==============================] - 0s 619us/step - loss: 0.6760 - acc: 0.6266 - precision: 0.7894 - val_loss: 0.5940 - val_acc: 0.7724 - val_precision: 0.7724
Epoch 3/5

128/624 [=====>........................] - ETA: 0s - loss: 0.6485 - acc: 0.7344 - precision: 0.8269
256/624 [===========>..................] - ETA: 0s - loss: 0.6490 - acc: 0.6992 - precision: 0.8006
384/624 [=================>............] - ETA: 0s - loss: 0.6476 - acc: 0.6771 - precision: 0.7969
512/624 [=======================>......] - ETA: 0s - loss: 0.6480 - acc: 0.6777 - precision: 0.7976
624/624 [==============================] - 0s 597us/step - loss: 0.6470 - acc: 0.6731 - precision: 0.7901 - val_loss: 0.6054 - val_acc: 0.7821 - val_precision: 0.7800
Epoch 4/5

128/624 [=====>........................] - ETA: 0s - loss: 0.6101 - acc: 0.7578 - precision: 0.8073
256/624 [===========>..................] - ETA: 0s - loss: 0.6142 - acc: 0.7578 - precision: 0.8073
384/624 [=================>............] - ETA: 0s - loss: 0.6175 - acc: 0.7422 - precision: 0.8049
512/624 [=======================>......] - ETA: 0s - loss: 0.6158 - acc: 0.7480 - precision: 0.8023
624/624 [==============================] - 0s 617us/step - loss: 0.6146 - acc: 0.7532 - precision: 0.8116 - val_loss: 0.5897 - val_acc: 0.7756 - val_precision: 0.8187
Epoch 5/5

128/624 [=====>........................] - ETA: 0s - loss: 0.5873 - acc: 0.7891 - precision: 0.8532
256/624 [===========>..................] - ETA: 0s - loss: 0.5924 - acc: 0.7930 - precision: 0.8402
384/624 [=================>............] - ETA: 0s - loss: 0.5865 - acc: 0.7995 - precision: 0.8427
624/624 [==============================] - 0s 553us/step - loss: 0.5711 - acc: 0.8189 - precision: 0.8461 - val_loss: 0.4870 - val_acc: 0.8077 - val_precision: 0.8007
Y_test =  [0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1
 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1
 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1
 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1
 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1
 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]
predictions1 =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Scores calculated from sklearn::
accuracy_score:  0.7644230769230769
precision_score:  0.7681159420289855
recall_score:  0.99375
