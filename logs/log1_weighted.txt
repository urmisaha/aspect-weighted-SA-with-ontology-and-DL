Processing text dataset
len(aspect_term_list) 1007

aspect_weights:
{'food': 0.9220246238030096, 'service': 0.89247311827957, 'price': 0.8585526315789473, 'ambience': 0.8368200836820083, 'misc': 0.9504412763068568}
(1673, 2)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 40, 20)            69440     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               48400     
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 202       
=================================================================
Total params: 118,042
Trainable params: 118,042
Non-trainable params: 0
_________________________________________________________________
None
Train on 1673 samples, validate on 1673 samples
Epoch 1/5

 128/1673 [=>............................] - ETA: 8s - loss: 0.6815 - acc: 0.6719
 256/1673 [===>..........................] - ETA: 4s - loss: 0.6615 - acc: 0.6836
 384/1673 [=====>........................] - ETA: 2s - loss: 0.6197 - acc: 0.7266
 640/1673 [==========>...................] - ETA: 1s - loss: 0.5882 - acc: 0.7438
 768/1673 [============>.................] - ETA: 1s - loss: 0.5747 - acc: 0.7513
 896/1673 [===============>..............] - ETA: 0s - loss: 0.5652 - acc: 0.7556
1152/1673 [===================>..........] - ETA: 0s - loss: 0.5749 - acc: 0.7517
1280/1673 [=====================>........] - ETA: 0s - loss: 0.5653 - acc: 0.7570
1408/1673 [========================>.....] - ETA: 0s - loss: 0.5518 - acc: 0.7656
1536/1673 [==========================>...] - ETA: 0s - loss: 0.5592 - acc: 0.7604
1664/1673 [============================>.] - ETA: 0s - loss: 0.5606 - acc: 0.7590
1673/1673 [==============================] - 2s 1ms/step - loss: 0.5605 - acc: 0.7591 - val_loss: 0.5411 - val_acc: 0.7609
Epoch 2/5

 128/1673 [=>............................] - ETA: 0s - loss: 0.5514 - acc: 0.7656
 256/1673 [===>..........................] - ETA: 0s - loss: 0.5596 - acc: 0.7500
 384/1673 [=====>........................] - ETA: 0s - loss: 0.5648 - acc: 0.7396
 512/1673 [========>.....................] - ETA: 0s - loss: 0.5466 - acc: 0.7598
 768/1673 [============>.................] - ETA: 0s - loss: 0.5395 - acc: 0.7669
 896/1673 [===============>..............] - ETA: 0s - loss: 0.5401 - acc: 0.7656
1024/1673 [=================>............] - ETA: 0s - loss: 0.5362 - acc: 0.7686
1152/1673 [===================>..........] - ETA: 0s - loss: 0.5320 - acc: 0.7708
1408/1673 [========================>.....] - ETA: 0s - loss: 0.5410 - acc: 0.7628
1536/1673 [==========================>...] - ETA: 0s - loss: 0.5445 - acc: 0.7598
1664/1673 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.7602
1673/1673 [==============================] - 1s 596us/step - loss: 0.5441 - acc: 0.7609 - val_loss: 0.5391 - val_acc: 0.7609
Epoch 3/5

 128/1673 [=>............................] - ETA: 0s - loss: 0.4381 - acc: 0.8516
 256/1673 [===>..........................] - ETA: 0s - loss: 0.5281 - acc: 0.7812
 384/1673 [=====>........................] - ETA: 0s - loss: 0.5245 - acc: 0.7760
 640/1673 [==========>...................] - ETA: 0s - loss: 0.5197 - acc: 0.7781
 768/1673 [============>.................] - ETA: 0s - loss: 0.5293 - acc: 0.7708
 896/1673 [===============>..............] - ETA: 0s - loss: 0.5337 - acc: 0.7690
1152/1673 [===================>..........] - ETA: 0s - loss: 0.5416 - acc: 0.7604
1408/1673 [========================>.....] - ETA: 0s - loss: 0.5392 - acc: 0.7628
1536/1673 [==========================>...] - ETA: 0s - loss: 0.5399 - acc: 0.7624
1664/1673 [============================>.] - ETA: 0s - loss: 0.5408 - acc: 0.7614
1673/1673 [==============================] - 1s 557us/step - loss: 0.5413 - acc: 0.7609 - val_loss: 0.5359 - val_acc: 0.7609
Epoch 4/5

 128/1673 [=>............................] - ETA: 0s - loss: 0.4833 - acc: 0.7891
 256/1673 [===>..........................] - ETA: 0s - loss: 0.4719 - acc: 0.8125
 512/1673 [========>.....................] - ETA: 0s - loss: 0.5047 - acc: 0.7852
 640/1673 [==========>...................] - ETA: 0s - loss: 0.5160 - acc: 0.7750
 768/1673 [============>.................] - ETA: 0s - loss: 0.5208 - acc: 0.7721
1024/1673 [=================>............] - ETA: 0s - loss: 0.5379 - acc: 0.7559
1280/1673 [=====================>........] - ETA: 0s - loss: 0.5387 - acc: 0.7555
1408/1673 [========================>.....] - ETA: 0s - loss: 0.5349 - acc: 0.7592
1536/1673 [==========================>...] - ETA: 0s - loss: 0.5402 - acc: 0.7546
1673/1673 [==============================] - 1s 514us/step - loss: 0.5353 - acc: 0.7609 - val_loss: 0.5310 - val_acc: 0.7609
Epoch 5/5

 128/1673 [=>............................] - ETA: 0s - loss: 0.5437 - acc: 0.7500
 256/1673 [===>..........................] - ETA: 0s - loss: 0.5917 - acc: 0.7031
 384/1673 [=====>........................] - ETA: 0s - loss: 0.5698 - acc: 0.7214
 640/1673 [==========>...................] - ETA: 0s - loss: 0.5606 - acc: 0.7344
 768/1673 [============>.................] - ETA: 0s - loss: 0.5493 - acc: 0.7435
 896/1673 [===============>..............] - ETA: 0s - loss: 0.5443 - acc: 0.7455
1024/1673 [=================>............] - ETA: 0s - loss: 0.5436 - acc: 0.7471
1280/1673 [=====================>........] - ETA: 0s - loss: 0.5317 - acc: 0.7570
1408/1673 [========================>.....] - ETA: 0s - loss: 0.5345 - acc: 0.7543
1536/1673 [==========================>...] - ETA: 0s - loss: 0.5357 - acc: 0.7546
1664/1673 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.7614
1673/1673 [==============================] - 1s 592us/step - loss: 0.5272 - acc: 0.7609 - val_loss: 0.5224 - val_acc: 0.7609
predictions =  [[0.22130555 0.7786945 ]
 [0.1857022  0.81429774]
 [0.16710997 0.83289   ]
 ...
 [0.21118027 0.78881973]
 [0.18028705 0.81971294]
 [0.36335716 0.6366429 ]]
predictions1 =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Scores calculated from sklearn::
accuracy_score:  0.24349442379182157
precision_score:  0.0
recall_score:  0.0

Classification Report:
             precision    recall  f1-score   support

          0       0.24      1.00      0.39       131
          1       0.00      0.00      0.00       407

avg / total       0.06      0.24      0.10       538

